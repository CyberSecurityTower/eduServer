
// services/ai/managers/memoryManager.js
'use strict';

const supabase = require('../../data/supabase');
const { nowISO } = require('../../data/dbUtils');
const { extractTextFromResult, ensureJsonOrRepair, safeSnippet } = require('../../../utils');
const logger = require('../../../utils/logger');
const PROMPTS = require('../../../config/ai-prompts');
const { getProfile } = require('../../data/helpers');

let embeddingServiceRef = null;
let generateWithFailoverRef = null;

const COLLECTION_NAME = 'user_memory_embeddings';

function initMemoryManager(initConfig = {}) {
  if (!initConfig.embeddingService || !initConfig.generateWithFailover) {
    throw new Error('Memory Manager requires embeddingService and generateWithFailover.');
  }
  embeddingServiceRef = initConfig.embeddingService;
  generateWithFailoverRef = initConfig.generateWithFailover;
  logger.info('Memory Manager Initialized (Smart Hybrid Mode).');
}

// Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø­ÙØ¸ Ø§Ù„ÙÙŠÙƒØªÙˆØ±
async function saveMemoryChunk(userId, content, type="General") {
  try {
    if (!embeddingServiceRef) return;
    const embedding = await embeddingServiceRef.generateEmbedding(content);
    if (!embedding || embedding.length === 0) return;

    await supabase.from('user_memory_embeddings').insert({
      user_id: userId,
      content: content,
      embedding: embedding,
      metadata: { type: type, source: 'smart_extractor' },
      created_at: nowISO()
    });
  } catch (err) {
    logger.error(`[Memory] Vector Save Error: ${err.message}`);
  }
}

async function runMemoryAgent(userId, userMessage, topK = 4) {
  try {
    if (!embeddingServiceRef) return '';

    const queryEmbedding = await embeddingServiceRef.generateEmbedding(userMessage);
    if (!queryEmbedding.length) return '';

    // RPC Call for Vector Search
    const similar = await embeddingServiceRef.findSimilarEmbeddings(
      queryEmbedding,
      COLLECTION_NAME,
      topK,
      userId
    );

    if (!similar || similar.length === 0) return '';

    const formatted = similar.map((m, i) => {
      return `[Memory ${i + 1}]: ${safeSnippet(m.originalText, 300)}`;
    }).join('\n');

    return `ğŸ§  **RELEVANT MEMORIES:**\n${formatted}`;
  } catch (error) {
    logger.error(`[Memory] Agent failed: ${error.message}`);
    return '';
  }
}

// 2. Structured Memory (Wrapper around helper)
// 2. Ø¯Ø§Ù„Ø© Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø°ÙƒÙŠØ© (Ù‡Ù†Ø§ Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ)

async function analyzeAndSaveMemory(userId, history) {
  try {
    if (!generateWithFailoverRef) return;

    // 1. Ø¬Ù„Ø¨ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    const profile = await getProfile(userId); // ØªØ£ÙƒØ¯ Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ¬Ù„Ø¨ Ø§Ù„Ù€ facts
    const currentFacts = profile.facts || {};

    // 2. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø´Ø§Øª
    const recentChat = history.slice(-10).map(m => `${m.role}: ${m.text}`).join('\n');

    // 3. Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù€ AI
    const prompt = PROMPTS.managers.memoryExtractor(currentFacts, recentChat);
    
    const res = await generateWithFailoverRef('analysis', prompt, { label: 'MemoryExtraction' });
    const text = await extractTextFromResult(res);
    const result = await ensureJsonOrRepair(text, 'analysis');

    if (!result) return;

    let hasChanges = false;
    let finalFacts = { ...currentFacts };

    // A. Ø­Ø°Ù Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£Ùˆ Ø§Ù„Ø®Ø§Ø·Ø¦Ø©
    if (result.deleteKeys && Array.isArray(result.deleteKeys)) {
        result.deleteKeys.forEach(key => {
            if (finalFacts[key]) {
                delete finalFacts[key];
                hasChanges = true;
                logger.info(`ğŸ—‘ï¸ Memory: Deleted key '${key}' for user ${userId}`);
            }
        });
    }

    // B. Ø¥Ø¶Ø§ÙØ©/ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    if (result.newFacts && Object.keys(result.newFacts).length > 0) {
        finalFacts = { ...finalFacts, ...result.newFacts };
        hasChanges = true;
        logger.success(`ğŸ’¾ Memory: Added/Updated facts for ${userId}`, result.newFacts);
    }

    // 4. Ø§Ù„Ø­ÙØ¸ ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØºÙŠÙŠØ±
    if (hasChanges) {
        const { error } = await supabase.from('ai_memory_profiles').upsert({
            user_id: userId,
            facts: finalFacts,
            last_analyzed_at: nowISO()
        });
        
        if (!error) {
            // ØªÙØ±ÙŠØº Ø§Ù„ÙƒØ§Ø´ Ù„ÙƒÙŠ ÙŠÙ‚Ø±Ø£ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª ÙÙˆØ±Ø§Ù‹
            const { cacheDel } = require('../../data/helpers');
            await cacheDel('profile', userId); 
        }
    }

    // 5. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ØµØµ (Vector Embeddings) - ÙƒÙ…Ø§ ÙƒØ§Ù† Ø³Ø§Ø¨Ù‚Ø§Ù‹
    if (result.vectorContent && result.vectorContent.length > 10) {
        await saveMemoryChunk(userId, result.vectorContent, "User Story");
    }

  } catch (err) {
    logger.error(`[Memory] Analysis Failed: ${err.message}`);
  }
}

/**
 * ğŸ§  Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Memory Garbage Collector)
 * ØªÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© ÙˆØ­Ø°Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª
 */
async function consolidateUserFacts(userId) {
  try {
    // 1. Ø¬Ù„Ø¨ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    const { data } = await supabase
        .from('ai_memory_profiles')
        .select('facts')
        .eq('user_id', userId)
        .single();

    const currentFacts = data?.facts || {};
    const keys = Object.keys(currentFacts);

    // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ù‚Ù„ÙŠÙ„Ø©ØŒ Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„Ù„Ø¯Ù…Ø¬
    if (keys.length < 5) return;

    logger.info(`ğŸ§¹ Consolidating memory for user ${userId}...`);

    // 2. Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø°ÙƒÙŠ
    const prompt = `
    You are a Database Optimizer. I have a JSON of user facts that might contain duplicates or outdated info.
    
    Current JSON: ${JSON.stringify(currentFacts)}
    
    Task:
    1. Merge related keys (e.g., "fav_subject": "Math" and "likes": "Mathematics" -> "favorite_subject": "Math").
    2. Remove redundant or weak facts.
    3. Keep the keys in English (snake_case).
    4. Output ONLY the cleaned JSON.
    `;

    // Ù†Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¯ÙŠÙ„ Ø°ÙƒÙŠ (Pro) Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
    const res = await generateWithFailoverRef('analysis', prompt, { label: 'MemoryConsolidation' });
    const text = await extractTextFromResult(res);
    const cleanedFacts = await ensureJsonOrRepair(text, 'analysis');

    if (cleanedFacts && Object.keys(cleanedFacts).length > 0) {
        // 3. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
        await supabase
            .from('ai_memory_profiles')
            .update({ 
                facts: cleanedFacts,
                last_optimized_at: new Date().toISOString()
            })
            .eq('user_id', userId);
            
        logger.success(`âœ¨ Memory optimized for ${userId}. Keys reduced from ${keys.length} to ${Object.keys(cleanedFacts).length}.`);
    }

  } catch (err) {
    logger.error('Memory Consolidation Error:', err.message);
  }
}
/**
 * ğŸ§  Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Memory Garbage Collector)
 * ØªÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© ÙˆØ­Ø°Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª
 */
async function consolidateUserFacts(userId) {
  try {
    // 1. Ø¬Ù„Ø¨ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    const { data } = await supabase
        .from('ai_memory_profiles')
        .select('facts')
        .eq('user_id', userId)
        .single();

    const currentFacts = data?.facts || {};
    const keys = Object.keys(currentFacts);

    // Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ù‚Ù„ÙŠÙ„Ø©ØŒ Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„Ù„Ø¯Ù…Ø¬
    if (keys.length < 5) return;

    logger.info(`ğŸ§¹ Consolidating memory for user ${userId}...`);

    // 2. Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø°ÙƒÙŠ
    const prompt = `
    You are a Database Optimizer. I have a JSON of user facts that might contain duplicates or outdated info.
    
    Current JSON: ${JSON.stringify(currentFacts)}
    
    Task:
    1. Merge related keys (e.g., "fav_subject": "Math" and "likes": "Mathematics" -> "favorite_subject": "Math").
    2. Remove redundant or weak facts.
    3. Keep the keys in English (snake_case).
    4. Output ONLY the cleaned JSON.
    `;

    // Ù†Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ¯ÙŠÙ„ Ø°ÙƒÙŠ (Pro) Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
    const res = await generateWithFailoverRef('analysis', prompt, { label: 'MemoryConsolidation' });
    const text = await extractTextFromResult(res);
    const cleanedFacts = await ensureJsonOrRepair(text, 'analysis');

    if (cleanedFacts && Object.keys(cleanedFacts).length > 0) {
        // 3. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©
        await supabase
            .from('ai_memory_profiles')
            .update({ 
                facts: cleanedFacts,
                last_optimized_at: new Date().toISOString()
            })
            .eq('user_id', userId);
            
        logger.success(`âœ¨ Memory optimized for ${userId}. Keys reduced from ${keys.length} to ${Object.keys(cleanedFacts).length}.`);
    }

  } catch (err) {
    logger.error('Memory Consolidation Error:', err.message);
  }
}

module.exports = {
  initMemoryManager,
  saveMemoryChunk,
  runMemoryAgent,
  analyzeAndSaveMemory,
  consolidateUserFacts
  
};
