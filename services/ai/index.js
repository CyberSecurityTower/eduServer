// services/ai/index.js
'use strict';

const CONFIG = require('../../config');
const logger = require('../../utils/logger');
const { withTimeout, sleep } = require('../../utils'); 
const keyManager = require('./keyManager');
const liveMonitor = require('../monitoring/realtimeStats');

const MODEL_CASCADE = [
  'gemini-2.5-flash',
  'gemini-2.5-pro'
];

async function initializeModelPools() {
  await keyManager.init();
  logger.success('ğŸ¤– AI Engine: Model Pools & Key Manager Ready.');
}

/**
 * Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
 * @param {*} unused_instance - (Ù…ØªØ±ÙˆÙƒ Ù„Ù„ØªÙˆØ§ÙÙ‚)
 * @param {string} prompt - Ø§Ù„Ù†Øµ
 * @param {number} timeoutMs - Ù…Ù‡Ù„Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
 * @param {string} label - Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
 * @param {string} systemInstruction - ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
 * @param {Array} history - Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
 * @param {Array} attachments - Ù…ØµÙÙˆÙØ© Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª (ØµÙˆØ±/Ù…Ù„ÙØ§Øª) Ø¬Ø§Ù‡Ø²Ø©
 * @param {boolean} enableSearch - ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„
 */
async function _callModelInstance(unused_instance, prompt, timeoutMs, label, systemInstruction, history, attachments = [], enableSearch = false) {
  
  // Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª: Ø¶Ø¹Ù Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
  const totalKeys = keyManager.getKeyCount() || 5; 
  const MAX_ATTEMPTS = totalKeys * 2; 
  let lastError = null;

  for (let attempt = 0; attempt < MAX_ATTEMPTS; attempt++) {
    let keyObj = null;
    try {
      keyObj = await keyManager.acquireKey();
      
      for (const modelName of MODEL_CASCADE) {
        try {
          
          // 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£Ø¯ÙˆØ§Øª (Google Search)
          const tools = [];
          if (enableSearch) {
              tools.push({ googleSearch: {} }); // ğŸ” ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø«
          }

          const model = keyObj.client.getGenerativeModel({ 
            model: modelName,
            systemInstruction: systemInstruction,
            tools: tools // Ù†Ù…Ø±Ø± Ø§Ù„Ø£Ø¯ÙˆØ§Øª
          });

          const generationConfig = { 
            temperature: 0.4,
            topP: 0.8,
            topK: 40
          };

          const chat = model.startChat({
            history: history || [],
            generationConfig
          });

          // 2. ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø±Ø³Ø§Ù„Ø© (Ù†Øµ + Ù…Ø±ÙÙ‚Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©)
          let messageParts = [];

          // âœ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ: Ø¯Ù…Ø¬ Ù…ØµÙÙˆÙØ© Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª (Ø³ÙˆØ§Ø¡ ÙƒØ§Ù†Øª ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ø£Ùˆ 10)
          if (attachments && Array.isArray(attachments) && attachments.length > 0) {
             console.log(`ğŸ“ [AI Service] Injecting ${attachments.length} attachments into prompt.`);
             // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù‡ÙŠÙƒÙ„ (Google GenAI ÙŠØªØ·Ù„Ø¨ inlineData)
             attachments.forEach((att, idx) => {
                 if (!att.inlineData || !att.inlineData.data || !att.inlineData.mimeType) {
                     console.error(`âš ï¸ [AI Service] Invalid attachment format at index ${idx}:`, JSON.stringify(att));
                 }
             });
             messageParts.push(...attachments);
          }

          // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Øµ (Prompt)
          if (prompt) {
             messageParts.push({ text: typeof prompt === 'string' ? prompt : JSON.stringify(prompt) });
          }

          // ğŸ›‘ DEBUG: Ø·Ø¨Ø§Ø¹Ø© Ù…Ø§ Ø³ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„Ù‡ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø¨Ø¯ÙˆÙ† Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù€ Base64 Ø§Ù„Ø·ÙˆÙŠÙ„)
          const debugParts = messageParts.map(p => {
              if (p.inlineData) return { type: 'image', mime: p.inlineData.mimeType, size: p.inlineData.data.length };
              return { type: 'text', content: p.text ? p.text.substring(0, 50) + '...' : '...' };
          });
          console.log('ğŸ¤– [AI Service] Final MessageParts to Model:', JSON.stringify(debugParts, null, 2));


          // 3. Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
          const result = await withTimeout(
            chat.sendMessage(messageParts),
            timeoutMs,
            `${label} [${modelName}]`
          );

          const response = await result.response;
          const successText = response.text();

          // 4. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ
          const usageMetadata = response.usageMetadata ?? result?.usageMetadata;
          if (usageMetadata) {
            keyManager.recordUsage(keyObj.key, usageMetadata, null, modelName);
          }
           
          // ØªØ¹Ù‚Ø¨ Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ù„Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯)
          const totalTokens = (usageMetadata?.promptTokenCount || 0) + (usageMetadata?.candidatesTokenCount || 0);
          liveMonitor.trackAiGeneration(totalTokens);

          // Ù†Ø¬Ø§Ø­! Ø­Ø±Ø± Ø§Ù„Ù…ÙØªØ§Ø­
          keyManager.releaseKey(keyObj.key, true);
          return successText;

        } catch (modelErr) {
            // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙƒÙˆØªØ§ (429)
             if (String(modelErr).includes('429') || String(modelErr).includes('Quota') || String(modelErr).includes('403')) {
             throw modelErr; 
          }
           logger.warn(`âš ï¸ Model ${modelName} hiccup on key ${keyObj.nickname}. Trying next...`);
        }
      }
      throw new Error('All models failed on this key');

    } catch (keyErr) {
        lastError = keyErr;
        const isRateLimit = String(keyErr).includes('429') || String(keyErr).includes('Quota') || String(keyErr).includes('403');
        
        if (keyObj) {
            keyManager.releaseKey(keyObj.key, false, isRateLimit ? '429' : 'error');
        }

        if (isRateLimit) { 
            await sleep(100); 
            continue; 
        } else { 
            break; 
        }
    }
  }
  
  throw lastError ?? new Error('Service Busy: All keys exhausted.');
}

module.exports = {
  initializeModelPools,
  _callModelInstance
};
