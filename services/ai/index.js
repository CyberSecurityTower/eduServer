// services/ai/index.js
'use strict';

const CONFIG = require('../../config');
const logger = require('../../utils/logger');
const { withTimeout, sleep } = require('../../utils');
const keyManager = require('./keyManager');

async function initializeModelPools() {
  await keyManager.init();
  const count = keyManager.getKeyCount();
  logger.success(`ğŸ¤– AI Engine: Google Only Mode | Loaded ${count} Keys`);
}

async function _callModelInstance(targetModelName, prompt, timeoutMs, label, systemInstruction, history, attachments, enableSearch) {
  
  // Ø³Ù†Ø­Ø§ÙˆÙ„ Ø­ØªÙ‰ 3 Ù…Ø±Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØ§ØªÙŠØ­ Ù…Ø®ØªÙ„ÙØ© ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø£Ø­Ø¯Ù‡Ø§
  const MAX_RETRIES = 3; 

  for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {
      
      // Ø·Ù„Ø¨ Ù…ÙØªØ§Ø­ Ù…Ù† Ø§Ù„Ù…Ø¯ÙŠØ±
      const keyObj = await keyManager.acquireKey(); // Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„ØªÙ…Ø±ÙŠØ± 'google'
      
      if (!keyObj) {
          if (attempt === 1) throw new Error('No Available AI Keys! System overloaded.');
          await sleep(1000); 
          continue; 
      }

      try {
          // Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø£Ùˆ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
          const selectedModel = targetModelName || 'gemini-1.5-flash';
          
          if(attempt > 1) logger.warn(`ğŸ”„ Retry ${attempt}/${MAX_RETRIES} for [${label}] using Key: ${keyObj.nickname}...`);
          
          const genAI = keyObj.client;
          const tools = enableSearch ? [{ googleSearch: {} }] : [];
          
          const model = genAI.getGenerativeModel({ 
              model: selectedModel,
              systemInstruction,
              tools: tools 
          });

          const chat = model.startChat({ 
              history: history || [],
              generationConfig: { temperature: 0.7 }
          });

          let parts = [];
          if (attachments?.length) parts.push(...attachments);
          // Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Øµ
          if (prompt) parts.push({ text: typeof prompt === 'string' ? prompt : JSON.stringify(prompt) });

          const result = await withTimeout(
              chat.sendMessage(parts),
              timeoutMs || 60000,
              `Gemini_Call`
          );
          
          const response = await result.response;
          const responseText = response.text();

          // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØµØ§Ø¯Ø± (Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø­Ø«)
          let sources = [];
          if (enableSearch && response.candidates?.[0]?.groundingMetadata?.groundingChunks) {
              sources = response.candidates[0].groundingMetadata.groundingChunks
                  .map(c => c.web ? { title: c.web.title, url: c.web.uri } : null)
                  .filter(Boolean);
          }

          // âœ… Ù†Ø¬Ø§Ø­
          keyManager.releaseKey(keyObj.key, true);
          return { text: responseText, sources: sources };

      } catch (err) {
          const errStr = String(err);
          let errType = 'error';

          // ØªØµÙ†ÙŠÙ Ø§Ù„Ø®Ø·Ø£
          if (errStr.includes('429') || errStr.includes('Quota')) errType = '429';
          else if (errStr.includes('Candidate was stopped')) errType = 'safety';

          logger.warn(`âŒ FAIL: Key ${keyObj.nickname}. Reason: ${errType}`);
          
          // ØªØ­Ø±ÙŠØ± Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ÙØ´Ù„
          keyManager.releaseKey(keyObj.key, false, errType);
          
          // Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ± Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
          await sleep(500);
      }
  }

  // Ø¥Ø°Ø§ ÙˆØµÙ„Ù†Ø§ Ù‡Ù†Ø§ØŒ ÙŠØ¹Ù†ÙŠ ÙØ´Ù„Øª ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
  logger.error(`ğŸ’€ AI SYSTEM FAIL: All ${MAX_RETRIES} attempts failed.`);
  throw new Error('Service Busy: Unable to generate response after multiple attempts.');
}

module.exports = {
  initializeModelPools,
  _callModelInstance
};
